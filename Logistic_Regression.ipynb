{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "- Logistic Regression is a statistical method used for binary classification problems where the outcome (dependent variable) is categorical (e.g., Yes/No, 0/1).\n",
        "\n",
        "- It predicts the probability of an event occurring using the Sigmoid function and outputs values between 0 and 1.\n",
        "\n",
        "- In contrast, Linear Regression predicts continuous numerical values by fitting a line (or hyperplane) using the formula:\n",
        "y = b0 + b1*x1 + b2*x2 + ... + bn*xn\n",
        "- Key difference:\n",
        "    - Linear Regression:-\n",
        "       - 1.Predicts continuous values\n",
        "       - 2.No restriction on output range\n",
        "       - 3.Uses Mean Squared Error (MSE) as loss function\n",
        "    - Logistic Regression:-\n",
        "       - 1.Predicts probabilities of classes (binary or multiclass)\n",
        "       - 2.Output constrained between 0 and 1\n",
        "       - 3.Uses Log Loss (Cross-Entropy) as loss function\n",
        "\n",
        "2. Explain the role of the Sigmoid function in Logistic Regression.\n",
        "- The Sigmoid function maps any real-valued number into the range (0, 1), making it perfect for representing probabilities.\n",
        "Formula:\n",
        "\n",
        "ùúé(ùëß)=1/(1+ùëí^z)\n",
        "\n",
        "Where z = b0 + b1*x1 + b2*x2 + ... + bn*xn (linear combination of features).\n",
        "\n",
        "When z is large and positive ‚Üí output close to 1 (high probability of class 1).\n",
        "\n",
        "When z is large and negative ‚Üí output close to 0 (high probability of class 0).\n",
        "\n",
        "Thus, it helps convert linear predictions into probabilities for classification.\n",
        "\n",
        "3. What is Regularization in Logistic Regression and why is it needed?\n",
        "- Regularization is a technique used to prevent overfitting by penalizing large coefficients in the model.\n",
        "Two common types:\n",
        "\n",
        "  1. L1 Regularization (Lasso): Adds absolute value of coefficients to the loss function.\n",
        "\n",
        "  2. L2 Regularization (Ridge): Adds squared value of coefficients to the loss function.\n",
        "\n",
        "- Why needed?\n",
        "\n",
        " - In high-dimensional data or noisy datasets, models tend to overfit, capturing noise instead of the signal.\n",
        "\n",
        " - Regularization forces the model to keep coefficients small, improving generalization on unseen data.\n",
        "\n",
        " 4. What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        "- Some common evaluation metrics:\n",
        "   - Accuracy: Fraction of correctly predicted instances.\n",
        "   - Precision: Proportion of true positive predictions among all positive predictions.\n",
        "   Precision=TP/(TP+FP)\n",
        "   - Recall (Sensitivity): Proportion of true positive predictions among all actual positives.\n",
        "   Recall=TP/(TP+FN)\n",
        "   - F1 Score: Harmonic mean of Precision and Recall.\n",
        "   F1¬†Score=2√ó(Precision√óRecall)/(Precision+Recall‚Äã‚Äã)\n",
        "- Importance:\n",
        "   - Especially important in imbalanced datasets where accuracy alone is misleading.\n",
        "   - Precision and Recall focus on minimizing false positives/negatives, essential for business decisions.\n",
        "\t‚Äã\n"
      ],
      "metadata": {
        "id": "AEnDBSlisl08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package)\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOMru6T51ocw",
        "outputId": "54db2d95-ee45-429a-de6f-d444e6bda0c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6 Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model Coefficients:\", model.coef_)\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(f\"Accuracy with L2 Regularization: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRuM450_2Gz5",
        "outputId": "9f4f2e80-2ad1-4d01-f8af-68c57c6f9834"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients: [[ 2.13248406e+00  1.52771940e-01 -1.45091255e-01 -8.28669349e-04\n",
            "  -1.42636015e-01 -4.15568847e-01 -6.51940282e-01 -3.44456106e-01\n",
            "  -2.07613380e-01 -2.97739324e-02 -5.00338038e-02  1.44298427e+00\n",
            "  -3.03857384e-01 -7.25692126e-02 -1.61591524e-02 -1.90655332e-03\n",
            "  -4.48855442e-02 -3.77188737e-02 -4.17516190e-02  5.61347410e-03\n",
            "   1.23214996e+00 -4.04581097e-01 -3.62091502e-02 -2.70867580e-02\n",
            "  -2.62630530e-01 -1.20898539e+00 -1.61796947e+00 -6.15250835e-01\n",
            "  -7.42763610e-01 -1.16960181e-01]]\n",
            "Accuracy with L2 Regularization: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7 Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report. (Use Dataset from sklearn package)\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(multi_class='ovr', max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl75skqL2RYA",
        "outputId": "92f2ac3b-bf33-4400-8b9e-68058695abf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "grid = GridSearchCV(LogisticRegression(solver='liblinear', max_iter=10000),\n",
        "                    param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(f\"Validation Accuracy: {grid.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC9LWICX3Aax",
        "outputId": "a72aa9cd-eab1-4bba-8788-a2d39a1f0c9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Validation Accuracy: 0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "model1 = LogisticRegression(max_iter=10000)\n",
        "model1.fit(X_train, y_train)\n",
        "acc_without_scaling = model1.score(X_test, y_test)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model2 = LogisticRegression(max_iter=10000)\n",
        "model2.fit(X_train_scaled, y_train)\n",
        "acc_with_scaling = model2.score(X_test_scaled, y_test)\n",
        "print(f\"Accuracy without Scaling: {acc_without_scaling:.4f}\")\n",
        "print(f\"Accuracy with Scaling: {acc_with_scaling:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-JvNkTe3OQv",
        "outputId": "ca27a5f8-0cc5-45f0-a079-1bc9907f7e71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 1.0000\n",
            "Accuracy with Scaling: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. : Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you‚Äôd take to build a\n",
        "Logistic Regression model ‚Äî including data handling, feature scaling, balancing\n",
        "classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case.\n",
        "\n",
        "- Data Handling: Collect customer behavior features (demographics, previous purchases, interactions, etc.).\n",
        "\n",
        "- Target variable: Response to marketing campaign (1 = Respond, 0 = No response).\n",
        "\n",
        "- Feature Scaling: Apply StandardScaler or MinMaxScaler to normalize data for better convergence.\n",
        "\n",
        "- Handling Imbalance: Use techniques like SMOTE (Synthetic Minority Over-sampling Technique) to balance the classes.\n",
        "\n",
        "  Alternatively, use class weighting in LogisticRegression (class_weight='balanced').\n",
        "\n",
        "- Hyperparameter Tuning: Apply GridSearchCV to optimize regularization strength (C) and penalty type.\n",
        "\n",
        "- Model Evaluation:\n",
        "  Do not rely on accuracy (since 95% of customers are non-responders).\n",
        "  Focus on Precision, Recall, F1 Score, ROC-AUC Score.\n",
        "  High recall is important to catch as many responders as possible.\n",
        "\n",
        "- Deployment Consideration: Periodically retrain model with fresh data to adapt to changing customer behavior."
      ],
      "metadata": {
        "id": "_GBJ4wWV38bO"
      }
    }
  ]
}